## This is the main Vars file for configuring cluster ##

cluster_name: cluster1
cluster_ip: "172.16.1.5"
netmask: "255.255.255.0"
username: "admin"
password: "Netapp1!"
https_global: "true"
validate_certs_global: "false"
domain: "demo.netapp.com"
timezone: "Asia/Jerusalem"
ntp: "dc1.demo.netapp.com"
ca_cert_filepath: "/home/user/aws_root.cer"
domain_tunnel_vserver: "svm_azurecvoha"
log_forward:
  destination: 10.0.0.1
  port: 514
  protocol: udp_unencrypted
  facility: user
hosts:
  node1:
    name: "cluster1-01"
    mgmt_ip: "172.16.1.17"
    subnet: "255.255.255.0"
    gateway: "192.168.0.1"
  node2:
    name: "cluster1-02"
    mgmt_ip: "172.16.1.17"
    subnet: "255.255.255.0"
    gateway: "192.168.0.1"
    cluster:
      private_ip: 169.254.10.11   # DO NOT CHANGE
      netmask: 255.255.0.0        # DO NOT CHANGE
      home_port: e0a

autoSupport:
 - {node_name: "azurecvoha-01", transport: https, noteto: "abc@def.com,def@ghi.com", mail_hosts: "mail@demo.netapp.com"}
 - {node_name: "azurecvoha-02", transport: https, noteto: "abc@def.com,def@ghi.com", mail_hosts: "mail@demo.netapp.com"}

dns:
  - { dns_domains: "{{ domain }}", dns_nameservers: y.y.y.y, vserver: "{{ cluster_name }}"}
  - { dns_domains: "{{ domain }}", dns_nameservers: y.y.y.y, vserver: svm1}
  - { dns_domains: "{{ domain }}", dns_nameservers: y.y.y.y, vserver: svm2}

cifsServer: # Join vserver to domain for cifs service
 - { vserver: svm_azurecvoha, cifs_server_name: cifs11, domain: "{{ domain }}", admin_user: "administrator", admin_password: "Netapp1!", ou: "CN=Computers", use_start_tls: true }

cifsMembers: # Join vserver to domain for cifs service
 - { vserver: svm_azurecvoha, group: 'BUILTIN\Administrators', member: 'demo\administrator'}

sslCertificate: # Join vserver to domain for cifs service
 - { vserver: svm_azurecvoha, common_name: ca.demo.netapp.com, name: ca, type: server_ca}

snapshotPolicy: # Join vserver to domain for cifs service
 - { policy: default, schedule: ['daily', 'weekly'], count: '[20, 30]', snapmirror_label: ['daily', 'weekly']}

exportrules:
  - { name: EP1, client_match: x.x.x.0/24, vserver: svm1 }
  - { name: EP2, client_match: x.x.x.0/24, vserver: svm1 }

nfs: 
  - { vserver: svm1, nfsv3: enabled, nfsv4: enabled, nfsv41: enabled, vstorage: enabled }
  - { vserver: svm2, nfsv3: enabled, nfsv4: enabled, nfsv41: enabled, vstorage: enabled }


igroup:
  - { name: ig1, initiator_group_type: iscsi, os_type: linux, initiator_names: "iqn.1995-08.com.example:string,iqn.1995-08.com.example:abcd.com", vserver: svm1}
  - { name: ig2, initiator_group_type: iscsi, os_type: linux, initiator_names: "iqn.1995-08.com.example:string", vserver: svm1}  

volumes:
  - { name: vol2, aggr: "{{ aggregates[0].name }}", size: 10, policy: default, junction_path: "/vol2", snappercent: 3, vserver: svm1, securitystyle: unix, snapshot_policy: default, sis_enable: true}
  - { name: vol3, aggr: "{{ aggregates[0].name }}", size: 10, policy: default, junction_path: "/vol3", snappercent: 3, vserver: svm1, securitystyle: unix, snapshot_policy: default, sis_enable: false}

FGvolumes:
  - { name: vol1_fg, aggr_list: "{{ aggregates[0].name }}", size: 10, policy: default, snappercent: 3, vserver: svm1, securitystyle: unix, aggr_list_multiplier: "2", snapshot_policy: default, sis_enable: true } # Felxgroup

luns:
  - { name: lun1, vserver: svm1, flexvol_name: "{{ volumes[0].name }}", size: 1, os_type: linux, space_reserve: true, space_allocation: true, igroup: ig1, lun_id: 0}
  - { name: lun2, vserver: svm1, flexvol_name: "{{ volumes[0].name }}", size: 1, os_type: linux, space_reserve: true, space_allocation: true, igroup: ig1, lun_id: 2}

snapshot_policy:
  - { name: snap_policy1, schedule: "hourly,weekly", count: "2,3", snapmirror_label: ""} # The schedule list is corresponding to count. means hourly-2 ; weekly-3

ports:
  - { node: "{{ hosts['node1'].name }}", port: e0c, mtu: 9000 , flowcontrol: none, autonegotiate: true}
  - { node: "{{ hosts['node1'].name }}", port: e0d, mtu: 9000 , flowcontrol: none, autonegotiate: true}
  - { node: "{{ hosts['node1'].name }}", port: e0e, mtu: 1500 , flowcontrol: none, autonegotiate: true}
  - { node: "{{ hosts['node1'].name }}", port: e0f, mtu: 1500 , flowcontrol: none, autonegotiate: true}
  - { node: "{{ hosts['node2'].name }}", port: e0c, mtu: 9000 , flowcontrol: none, autonegotiate: true}
  - { node: "{{ hosts['node2'].name }}", port: e0d, mtu: 9000 , flowcontrol: none, autonegotiate: true}
  - { node: "{{ hosts['node2'].name }}", port: e0e, mtu: 1500 , flowcontrol: none, autonegotiate: true}
  - { node: "{{ hosts['node2'].name }}", port: e0f, mtu: 1500 , flowcontrol: none, autonegotiate: true}

ifgrps:
  - { name: a0a, node: "{{ hosts['node1'].name }}", ports: "e0c,e0e", mode: multimode_lacp, mtu: 9000, distribution_function: ip }
  - { name: a0a, node: "{{ hosts['node2'].name }}", ports: "e0c,e0e", mode: multimode_lacp, mtu: 9000, distribution_function: ip }
  - { name: a0b, node: "{{ hosts['node1'].name }}", ports: "e0d,e0f", mode: multimode_lacp, mtu: 1500, distribution_function: ip }
  - { name: a0b, node: "{{ hosts['node2'].name }}", ports: "e0d,e0f", mode: multimode_lacp, mtu: 1500, distribution_function: ip }


vlans:
  - { vlanid: 300, node: "{{ hosts['node1'].name }}", phy_interface: "a0a" }
  - { vlanid: 400, node: "{{ hosts['node1'].name }}", phy_interface: "a0a" }
  - { vlanid: 62, node: "{{ hosts['node1'].name }}", phy_interface: "a0a" }
  - { vlanid: 300, node: "{{ hosts['node2'].name }}", phy_interface: "a0a" }
  - { vlanid: 400, node: "{{ hosts['node2'].name }}", phy_interface: "a0a" }
  - { vlanid: 62, node: "{{ hosts['node2'].name }}", phy_interface: "a0a" }

bcasts:
  - { name: vlan_400, ports: "{{hosts['node1'].name }}:a0a-400,{{hosts['node2'].name }}:a0a-400", mtu: 1500 }
  - { name: vlan_300, ports: "{{hosts['node1'].name }}:a0a-300,{{hosts['node2'].name }}:a0a-300", mtu: 1500 }

lifs:
  - { name: lif1, node: "{{ hosts['node1'].name }}", port: e0c, address: 192.168.0.230, netmask: 255.255.255.0, vserver: svm2, protocols: "nfs,cifs", dns_domain_name: "demo.netapp.com" }
  - { name: lif2, node: "{{ hosts['node2'].name }}", port: e0c, address: 192.168.0.231, netmask: 255.255.255.0, vserver: svm1, protocols: "nfs,cifs"}
  - { name: lif1, node: "{{ hosts['node2'].name }}", port: e0c, address: 192.168.0.232, netmask: 255.255.255.0, vserver: svm2, protocols: "nfs,cifs"}

routes: 
  - { vserver: "{{ cluster_name }}", destination: 0.0.0.0/0, gateway: x.x.x.254 }
  - { vserver: SVM_Beci, destination: 0.0.0.0/0, gateway: x.x.x.254 }
  - { vserver: SVM_David, destination: 0.0.0.0/0, gateway: y.y.y.254 }


cifsShares:
  - { share_name: share1, vol_path: "/vol2", vserver: svm1, share_properties: "browsable,oplocks,changenotify,show_previous_versions", symlink_properties: "enable" }
  - { share_name: share2, vol_path: "/vol3", vserver: svm1, share_properties: "browsable,oplocks,changenotify,show_previous_versions", symlink_properties: "enable" }


iscsi:
  - { vserver: svm1}
sp:
  - { node: "{{ hosts['node1'].name }}", dhcp: none, ip_enabled: true, address_type: ipv4, state: present, ip_address: x.x.x.x, netmask: 255.255.255.0, gateway: x.x.x.x }
  - { node: "{{ hosts['node2'].name }}", dhcp: none, ip_enabled: true, address_type: ipv4, state: present, ip_address: x.x.x.x, netmask: 255.255.255.0, gateway: x.x.x.x }

snmp:
  - { community_name: ansible_snmp, access_control: ro }

loginUsers:
  - { username: "vsadmin", password: "8LetterLength", apps: "http,ontapi,ssh", role: "vsadmin", vserver: "svm1"} # Enable vsadmin
  - { username: "test1", password: "8LetterLength", apps: "http", role: "readonly", vserver: "svm1"}
  - { username: "test2", password: "8LetterLength", apps: "http,ssh", role: "vsadmin", vserver: "svm1"}
